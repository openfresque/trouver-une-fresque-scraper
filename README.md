# trouver-une-fresque-scraper

Le scraper de Trouver une Fresque est un outil open source permettant de d√©tecter les ateliers disponibles dans votre d√©partement.

Les donn√©es sont extraites des billetteries officielles via la technique du scraping. La validit√© des adresses est v√©rifi√©e en utilisant les donn√©es d'OpenStreetMap.

Si vous utilisez ce code, merci de respecter la [charte de Nominatim](https://operations.osmfoundation.org/policies/nominatim/).

## üåç Organisateurs: signaler un probl√®me

Si vous √™tes l'organisateur d'un atelier Fresque et que votre √©v√®nement n'appara√Æt pas sur la plateforme Trouver une Fresque, merci de lire le [tutoriel √† destination des organisateurs de fresques](https://github.com/trouver-une-fresque/trouver-une-fresque/blob/main/TUTORIAL.md).

Ouvrez une [issue Github](https://github.com/thomas-bouvier/trouver-une-fresque/issues/new) si vous souhaitez signaler un probl√®me non couvert dans le tutoriel, ou sugg√©rer l'int√©gration d'un nouvel atelier.

Les ateliers actuellement support√©s sont list√©s sur la [feuille de route](WORKSHOPS.md).

## ü§ñ D√©veloppeurs: installation

Le scraping est effectu√© en utilisant Selenium, qui s'appuie sur geckodriver pour afficher les donn√©es √† r√©cup√©rer. Notre outil peut √™tre install√© sur un Raspberry Pi sans probl√®me.

### Avec `flox` (m√©thode recommand√©e)

Flox est un gestionnaire de paquets multiplateforme qui vise √† permettre la reproducibilit√©, la robustesse, la portabilit√© et la stabilit√© des syst√®mes d'information. Cette approche permet d'installer les paquets Python et d√©pendances syst√®me en une seule fois.

Suivez les instructions pour installer Flox sur votre syst√®me [ici](https://flox.dev/docs/install-flox/). Tout est pr√™t ! Utilisez la commande `flox activate` dans ce dossier pour commencer √† d√©velopper.

V√©rifiez que tout fonctionne:

```console
python -c "import trouver_une_fresque_scraper as m; print(m.__file__)"
```

### Manuellement avec `uv`

Cette m√©thode d'installation n'est pas recommand√©e. Pr√©f√©rez l'utilisation de Flox, qui vous facilitera la t√¢che et garantira d'avoir toutes les d√©pendances n√©cessaires pour lancer le scraper.

T√©l√©chargez la version la plus r√©cente de [geckodriver](https://github.com/mozilla/geckodriver/releases), puis extrayez le binaire `geckodriver` dans un dossier `bin/` (ou n'importe o√π sur votre syst√®me).

Les librairies suivantes doivent √™tre install√©es sur votre syst√®me:

```console
apt install firefox-esr libpq-dev python3-dev
```

Enfin, suivez les instructions pour installer `uv` [ici](https://docs.astral.sh/uv/getting-started/installation/) et cr√©ez un environnement Python:

```console
uv venv .venv --python 3.13
```

Activez l'environnement:

```console
source .venv/bin/activate
```

Installez le scraper avec:

```console
uv sync
```

V√©rifiez que tout fonctionne:

```console
python -c "import trouver_une_fresque_scraper as m; print(m.__file__)"
```

## ü§ñ D√©veloppeurs: utilisation

Avant de contribuer au projet, assurez-vous d'avoir lu le document [CONTRIBUTING.md](./CONTRIBUTING.md).

### Configuration

Renommez le fichier de configuration `config.json.dist` en `config.json` et renseignez les champs.

```json
{
    "webdriver": "",
    "host" : "",
    "port" : "",
    "user" : "",
    "psw"  : "",
    "database": "",
    "timezone": "Europe/Paris"
}
```

Le champ `webdriver` est √† renseigner avec le chemin vers le binaire `geckodriver` dans le cas d'une installation sans Flox (= manuelle avec `uv` uniquement) uniquement.


### Lancer le scraping

```console
python -m trouver_une_fresque_scraper.scrape
# or
python -m trouver_une_fresque_scraper.scrape --headless --country ch --skip-dirty-check
```

√Ä la fin du scraping, un fichier JSON nomm√© avec le format `events_20230814_153752.json` est cr√©√© dans le dossier `results/`.

L'option `--headless` ex√©cute le scraping en mode headless, et `--push-to-db` pousse les r√©sultats du fichier json de sortie dans la base de donn√©es en utilisant les identifiants d√©finis dans `config.json`.

### Base de donn√©es

Nous utilisons [Supabase](https://supabase.com/docs/guides/cli/local-development) pour persister les donn√©es scrap√©es, une alternative open source √† Firebase qui fournit une base de donn√©es Postgres gratuitement.

Login to the CLI and start the database. When starting the database, if file `supabase/seed.sql` is present, the `INSERT` statements will be executed to populate the database with testing data. 

```console
supabase login
supabase init
supabase start
```

The `supabase/tables.sql` contains SQL statements allowing to create the required tables. 

To push some data into the database, use the following command:

```console
python push_to_db.py --input results/output.json
```

This command will perform the following actions:

- All events are inserted into the historical table `events_scraped`. Setting `most_recent=False`, but maybe the call to `update_most_recent()` below will change this.
- Delete all events from `events_future` before inserting them again, so that they are updated. Setting `most_recent=True`.
- The `most_recent` attribute of events in `events_scraped` are set to `True` if the following conditions are met:
    - A query identifies rows in the `events_scraped` table that do not have a corresponding entry in the `events_future` table.
    - For these rows, it finds the most recent `scrape_date` for each `id` and `workshop_type`.
    - It then updates the `most_recent` column to `TRUE` for these rows, but only if the `start_date` of the event is in the past.

### Lancer les tests

```console
cd tests
python scrape_tests.py
```

## Comment contribuer

Pour proposer une modification, un ajout, ou d√©crire un bug sur l'outil de d√©tection, vous pouvez ouvrir une [issue](https://github.com/thomas-bouvier/trouver-une-fresque/issues/new) ou une [Pull Request](https://github.com/thomas-bouvier/trouver-une-fresque/pulls) avec vos modifications.

Avant de d√©velopper, merci d'installer le hook git en suivant les instructions list√©es dans le fichier [CONTRIBUTING](https://github.com/trouver-une-fresque/trouver-une-fresque/blob/main/CONTRIBUTING.md). Pour le code en Python, veillez √† respecter le standard PEP8 avant de soumettre une Pull Request. La plupart des IDEs et √©diteurs de code modernes proposent des outils permettant de mettre en page votre code en suivant ce standard automatiquement.
